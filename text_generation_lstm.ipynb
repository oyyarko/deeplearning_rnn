{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-generation-lstm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnvSyUmo8cFi/myMl0nY/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oyyarko/deeplearning_rnn/blob/master/text_generation_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yu6xWjQLlag",
        "colab_type": "code",
        "outputId": "a513bcf5-7fbe-40b1-93b4-bae903e9b3c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "tensorflow.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEJ_Yg9FMJPg",
        "colab_type": "code",
        "outputId": "99ad9eaf-5a98-4c89-cd43-5ac31b841ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "!wget https://www.gutenberg.org/files/11/11-0.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-29 08:35:24--  https://www.gutenberg.org/files/11/11-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174481 (170K) [text/plain]\n",
            "Saving to: ‘11-0.txt’\n",
            "\n",
            "11-0.txt            100%[===================>] 170.39K   112KB/s    in 1.5s    \n",
            "\n",
            "2020-03-29 08:35:27 (112 KB/s) - ‘11-0.txt’ saved [174481/174481]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGc4XOYSMkd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"wonderland.txt\"\n",
        "\n",
        "#with open(filename, 'r') as f:\n",
        "  #  raw_text = f.read()\n",
        "    #raw_text = raw_text.lower()\n",
        "    \n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wb1SN0NM5Zr",
        "colab_type": "code",
        "outputId": "ced0fd8a-0fc9-4166-ed79-7e96ec31436f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "chars_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_cahr = dict((i, c) for i, c in enumerate(chars))\n",
        "chars_to_int"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '#': 4,\n",
              " '$': 5,\n",
              " '%': 6,\n",
              " \"'\": 7,\n",
              " '(': 8,\n",
              " ')': 9,\n",
              " '*': 10,\n",
              " ',': 11,\n",
              " '-': 12,\n",
              " '.': 13,\n",
              " '/': 14,\n",
              " '0': 15,\n",
              " '1': 16,\n",
              " '2': 17,\n",
              " '3': 18,\n",
              " '4': 19,\n",
              " '5': 20,\n",
              " '6': 21,\n",
              " '7': 22,\n",
              " '8': 23,\n",
              " '9': 24,\n",
              " ':': 25,\n",
              " ';': 26,\n",
              " '?': 27,\n",
              " '@': 28,\n",
              " '[': 29,\n",
              " ']': 30,\n",
              " '_': 31,\n",
              " 'a': 32,\n",
              " 'b': 33,\n",
              " 'c': 34,\n",
              " 'd': 35,\n",
              " 'e': 36,\n",
              " 'f': 37,\n",
              " 'g': 38,\n",
              " 'h': 39,\n",
              " 'i': 40,\n",
              " 'j': 41,\n",
              " 'k': 42,\n",
              " 'l': 43,\n",
              " 'm': 44,\n",
              " 'n': 45,\n",
              " 'o': 46,\n",
              " 'p': 47,\n",
              " 'q': 48,\n",
              " 'r': 49,\n",
              " 's': 50,\n",
              " 't': 51,\n",
              " 'u': 52,\n",
              " 'v': 53,\n",
              " 'w': 54,\n",
              " 'x': 55,\n",
              " 'y': 56,\n",
              " 'z': 57,\n",
              " 'ù': 58,\n",
              " '—': 59,\n",
              " '‘': 60,\n",
              " '’': 61,\n",
              " '“': 62,\n",
              " '”': 63}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRHoDAwFN683",
        "colab_type": "code",
        "outputId": "161027d3-7507-4440-f25d-356cfe210626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Text: \", n_chars, \"\\nVocab: \", n_vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  164201 \n",
            "Vocab:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j504TGEnOmw1",
        "colab_type": "code",
        "outputId": "6d7e9e99-7b16-4301-d9cb-477030ec5a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i+seq_length]\n",
        "    seq_out = raw_text[i+seq_length]\n",
        "    dataX.append([chars_to_int[char] for char in seq_in])\n",
        "    dataY.append(chars_to_int[seq_out])\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Pattern: \", n_patterns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Pattern:  164101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6phkiQgnQp7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X/float(n_vocab)\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktL6mewwSVx0",
        "colab_type": "text"
      },
      "source": [
        "## LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6uwTLpHSUwu",
        "colab_type": "code",
        "outputId": "9b93ed51-9ca5-4a62-f54e-91dded38e595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 256)               264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "=================================================================\n",
            "Total params: 280,640\n",
            "Trainable params: 280,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVcZdIHoSOY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mze2kgxTS5Y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7HLowhwTlEJ",
        "colab_type": "code",
        "outputId": "25a03db1-08eb-49d2-c263-40cb7578bcac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.8597\n",
            "Epoch 00001: loss improved from inf to 2.85977, saving model to weights-improvement-01-2.8598.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.8598\n",
            "Epoch 2/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.7847\n",
            "Epoch 00002: loss improved from 2.85977 to 2.78494, saving model to weights-improvement-02-2.7849.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.7849\n",
            "Epoch 3/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.7193\n",
            "Epoch 00003: loss improved from 2.78494 to 2.71908, saving model to weights-improvement-03-2.7191.hdf5\n",
            "1283/1283 [==============================] - 24s 18ms/step - loss: 2.7191\n",
            "Epoch 4/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.6627\n",
            "Epoch 00004: loss improved from 2.71908 to 2.66197, saving model to weights-improvement-04-2.6620.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.6620\n",
            "Epoch 5/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.6096\n",
            "Epoch 00005: loss improved from 2.66197 to 2.60923, saving model to weights-improvement-05-2.6092.hdf5\n",
            "1283/1283 [==============================] - 24s 18ms/step - loss: 2.6092\n",
            "Epoch 6/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.5567\n",
            "Epoch 00006: loss improved from 2.60923 to 2.55666, saving model to weights-improvement-06-2.5567.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.5567\n",
            "Epoch 7/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.5132\n",
            "Epoch 00007: loss improved from 2.55666 to 2.51322, saving model to weights-improvement-07-2.5132.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.5132\n",
            "Epoch 8/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.4680\n",
            "Epoch 00008: loss improved from 2.51322 to 2.46830, saving model to weights-improvement-08-2.4683.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.4683\n",
            "Epoch 9/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.4289\n",
            "Epoch 00009: loss improved from 2.46830 to 2.42800, saving model to weights-improvement-09-2.4280.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.4280\n",
            "Epoch 10/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.3910\n",
            "Epoch 00010: loss improved from 2.42800 to 2.39134, saving model to weights-improvement-10-2.3913.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.3913\n",
            "Epoch 11/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.3550\n",
            "Epoch 00011: loss improved from 2.39134 to 2.35518, saving model to weights-improvement-11-2.3552.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.3552\n",
            "Epoch 12/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.3235\n",
            "Epoch 00012: loss improved from 2.35518 to 2.32260, saving model to weights-improvement-12-2.3226.hdf5\n",
            "1283/1283 [==============================] - 24s 18ms/step - loss: 2.3226\n",
            "Epoch 13/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.2915\n",
            "Epoch 00013: loss improved from 2.32260 to 2.29244, saving model to weights-improvement-13-2.2924.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.2924\n",
            "Epoch 14/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.2624\n",
            "Epoch 00014: loss improved from 2.29244 to 2.26143, saving model to weights-improvement-14-2.2614.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.2614\n",
            "Epoch 15/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.2335\n",
            "Epoch 00015: loss improved from 2.26143 to 2.23365, saving model to weights-improvement-15-2.2337.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.2337\n",
            "Epoch 16/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.2085\n",
            "Epoch 00016: loss improved from 2.23365 to 2.20831, saving model to weights-improvement-16-2.2083.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.2083\n",
            "Epoch 17/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.1834\n",
            "Epoch 00017: loss improved from 2.20831 to 2.18394, saving model to weights-improvement-17-2.1839.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.1839\n",
            "Epoch 18/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.1558\n",
            "Epoch 00018: loss improved from 2.18394 to 2.15541, saving model to weights-improvement-18-2.1554.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.1554\n",
            "Epoch 19/30\n",
            "1281/1283 [============================>.] - ETA: 0s - loss: 2.1325\n",
            "Epoch 00019: loss improved from 2.15541 to 2.13294, saving model to weights-improvement-19-2.1329.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.1329\n",
            "Epoch 20/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.1128\n",
            "Epoch 00020: loss improved from 2.13294 to 2.11349, saving model to weights-improvement-20-2.1135.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.1135\n",
            "Epoch 21/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.0907\n",
            "Epoch 00021: loss improved from 2.11349 to 2.08990, saving model to weights-improvement-21-2.0899.hdf5\n",
            "1283/1283 [==============================] - 24s 18ms/step - loss: 2.0899\n",
            "Epoch 22/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.0698\n",
            "Epoch 00022: loss improved from 2.08990 to 2.06954, saving model to weights-improvement-22-2.0695.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.0695\n",
            "Epoch 23/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.0482\n",
            "Epoch 00023: loss improved from 2.06954 to 2.04787, saving model to weights-improvement-23-2.0479.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.0479\n",
            "Epoch 24/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.0299\n",
            "Epoch 00024: loss improved from 2.04787 to 2.03055, saving model to weights-improvement-24-2.0305.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.0305\n",
            "Epoch 25/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 2.0146\n",
            "Epoch 00025: loss improved from 2.03055 to 2.01468, saving model to weights-improvement-25-2.0147.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 2.0147\n",
            "Epoch 26/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 1.9963\n",
            "Epoch 00026: loss improved from 2.01468 to 1.99657, saving model to weights-improvement-26-1.9966.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 1.9966\n",
            "Epoch 27/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 1.9782\n",
            "Epoch 00027: loss improved from 1.99657 to 1.97883, saving model to weights-improvement-27-1.9788.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 1.9788\n",
            "Epoch 28/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 1.9678\n",
            "Epoch 00028: loss improved from 1.97883 to 1.96782, saving model to weights-improvement-28-1.9678.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 1.9678\n",
            "Epoch 29/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 1.9515\n",
            "Epoch 00029: loss improved from 1.96782 to 1.95181, saving model to weights-improvement-29-1.9518.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 1.9518\n",
            "Epoch 30/30\n",
            "1282/1283 [============================>.] - ETA: 0s - loss: 1.9417\n",
            "Epoch 00030: loss improved from 1.95181 to 1.94188, saving model to weights-improvement-30-1.9419.hdf5\n",
            "1283/1283 [==============================] - 24s 19ms/step - loss: 1.9419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0161196a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgxgakunehwn",
        "colab_type": "text"
      },
      "source": [
        "## **Generating Text with LSTM network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWPF6GGlTro1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"weights-improvement-30-1.9419.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--PWZhVje66B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9d1c9c05-b643-46e2-c025-c97210cffa05"
      },
      "source": [
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"seed: \")\n",
        "print(\"\\\"\", ''.join([int_to_cahr[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed: \n",
            "\" l donations are gratefully accepted, but we cannot make\n",
            "any statements concerning tax treatment of d \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiCSqHcZf9DR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9e0bd50-6499-4e20-e04e-55bd900eff37"
      },
      "source": [
        "len(pattern)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOazuOrygHgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "54582cdf-1d66-4998-bd50-82b58e74c6df"
      },
      "source": [
        "import sys\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x/float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_cahr[index]\n",
        "    seq_in = [int_to_cahr[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"Done\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "onations wooes in pooaect gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works in poededt gutenberg-tm electronic works iDone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9WdOBsqg4ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}